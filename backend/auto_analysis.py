# auto_analysis.py - ×× ×”×œ × ×™×ª×•×—×™× ××•×˜×•××˜×™×™×
import os
import uuid
from datetime import datetime, timedelta
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger

class AutoAnalysisManager:
    """×× ×”×œ × ×™×ª×•×—×™× ××•×˜×•××˜×™×™× - ×‘×•×“×§ ×•××‘×¦×¢ × ×™×ª×•×—×™× ×œ×¤×™ ×œ×•×— ×–×× ×™×"""
    
    def __init__(self, db_manager, satellite_processor):
        self.db_manager = db_manager
        self.satellite_processor = satellite_processor
        self.scheduler = BackgroundScheduler()
        self.is_running = False
        
        # ×”×’×“×¨×•×ª ×‘×¨×™×¨×ª ××—×“×œ
        self.check_interval_hours = 1  # ×‘×“×™×§×” ×›×œ ×©×¢×”
        self.max_analyses_per_run = 10  # ××§×¡×™××•× × ×™×ª×•×—×™× ×‘×›×œ ×”×¨×¦×”
        
        print("ğŸ¤– ×× ×”×œ × ×™×ª×•×—×™× ××•×˜×•××˜×™ ××•×ª×—×œ")
    
    def start(self):
        """×”×ª×—×œ×ª ×”×©×™×¨×•×ª ×”××•×˜×•××˜×™"""
        if self.is_running:
            print("âš ï¸ ×”×©×™×¨×•×ª ×›×‘×¨ ×¤×•×¢×œ")
            return
        
        try:
            # ×”×•×¡×¤×ª ××©×™××” ×œ×‘×“×™×§×” ×ª×§×•×¤×ª×™×ª
            self.scheduler.add_job(
                func=self.check_and_run_analyses,
                trigger=IntervalTrigger(hours=self.check_interval_hours),
                id='auto_analysis_checker',
                name='×‘×•×“×§ × ×™×ª×•×—×™× ××•×˜×•××˜×™×™×',
                replace_existing=True,
                max_instances=1  # ×× ×¢ ×”×¤×¢×œ×•×ª ×›×¤×•×œ×•×ª
            )
            
            self.scheduler.start()
            self.is_running = True
            print(f"âœ… ×©×™×¨×•×ª × ×™×ª×•×—×™× ××•×˜×•××˜×™ ×”×—×œ - ×‘×“×™×§×” ×›×œ {self.check_interval_hours} ×©×¢×•×ª")
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×”×¤×¢×œ×ª ×©×™×¨×•×ª ××•×˜×•××˜×™: {e}")
    
    def stop(self):
        """×¢×¦×™×¨×ª ×”×©×™×¨×•×ª ×”××•×˜×•××˜×™"""
        if not self.is_running:
            print("âš ï¸ ×”×©×™×¨×•×ª ×œ× ×¤×•×¢×œ")
            return
        
        try:
            self.scheduler.shutdown(wait=True)
            self.is_running = False
            print("âœ… ×©×™×¨×•×ª × ×™×ª×•×—×™× ××•×˜×•××˜×™ × ×¢×¦×¨")
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×¢×¦×™×¨×ª ×©×™×¨×•×ª ××•×˜×•××˜×™: {e}")
    
    def check_and_run_analyses(self):
        """×‘×“×™×§×” ×•×”×¤×¢×œ×ª × ×™×ª×•×—×™× ×”×“×¨×•×©×™×"""
        try:
            print("ğŸ”„ ×‘×•×“×§ AOIs ×”×–×§×•×§×™× ×œ× ×™×ª×•×— ××•×˜×•××˜×™...")
            
            # ×§×‘×œ×ª ×¨×©×™××ª AOIs ×œ× ×™×ª×•×—
            aois_to_analyze = self.db_manager.get_aois_for_analysis()
            
            if not aois_to_analyze:
                print("ğŸ“Š ××™×Ÿ AOIs ×”×–×§×•×§×™× ×œ× ×™×ª×•×— ×›×¨×’×¢")
                return
            
            print(f"ğŸ¯ × ××¦××• {len(aois_to_analyze)} AOIs ×–×§×•×§×™× ×œ× ×™×ª×•×—")
            
            # ×”×’×‘×œ×ª ××¡×¤×¨ ×”× ×™×ª×•×—×™×
            analyses_to_run = aois_to_analyze[:self.max_analyses_per_run]
            if len(aois_to_analyze) > self.max_analyses_per_run:
                print(f"âš ï¸ ××’×‘×™×œ ×œ-{self.max_analyses_per_run} × ×™×ª×•×—×™× ×‘×”×¨×¦×” ×–×•")
            
            # ×”×¤×¢×œ×ª × ×™×ª×•×—×™×
            successful_analyses = 0
            failed_analyses = 0
            
            for aoi_data in analyses_to_run:
                try:
                    success = self.run_automatic_analysis(aoi_data)
                    if success:
                        successful_analyses += 1
                    else:
                        failed_analyses += 1
                        
                except Exception as e:
                    print(f"âŒ × ×™×ª×•×— ××•×˜×•××˜×™ × ×›×©×œ ×¢×‘×•×¨ AOI {aoi_data['name']}: {e}")
                    failed_analyses += 1
                    continue
            
            print(f"ğŸ“Š ×¡×™×›×•× ×”×¨×¦×”: {successful_analyses} ××•×¦×œ×—×™×, {failed_analyses} ×›×©×œ×•× ×•×ª")
                    
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×‘×•×“×§ × ×™×ª×•×—×™× ××•×˜×•××˜×™: {e}")
    
    def run_automatic_analysis(self, aoi_data):
        """×”×¤×¢×œ×ª × ×™×ª×•×— ××•×˜×•××˜×™ ×¢×‘×•×¨ AOI ×¡×¤×¦×™×¤×™"""
        aoi_id = aoi_data['aoi_id']
        user_id = aoi_data['user_db_id']
        aoi_name = aoi_data['name']
        bbox = aoi_data['bbox_coordinates']
        
        print(f"ğŸ›°ï¸ ××ª×—×™×œ × ×™×ª×•×— ××•×˜×•××˜×™ ×¢×‘×•×¨: {aoi_name}")
        
        try:
            # ×‘×“×™×§×” ×•×©×™××•×© ×‘×˜×•×§× ×™×
            success, message = self.db_manager.use_tokens(
                user_id, 
                1, 
                f"× ×™×ª×•×— ××•×˜×•××˜×™: {aoi_name}"
            )
            
            if not success:
                print(f"ğŸ’° ××™×Ÿ ××¡×¤×™×§ ×˜×•×§× ×™× ×¢×‘×•×¨ {aoi_name}: {message}")
                # ×¢×“×›×•×Ÿ ×ª××¨×™×š × ×™×ª×•×— ×”×‘× ×œ× ×™×¡×™×•×Ÿ ×××•×—×¨ ×™×•×ª×¨
                self.db_manager.update_aoi_analysis_date(aoi_id, increment_total=False)
                return False
            
            # ×™×¦×™×¨×ª ×˜×•×•×—×™ ×ª××¨×™×›×™× ×œ×”×©×•×•××”
            date_ranges = self.generate_date_ranges()
            
            # ×”×•×¨×“×ª ×ª××•× ×•×ª
            print(f"ğŸ“¥ ××•×¨×™×“ ×ª××•× ×” ×”×™×¡×˜×•×¨×™×ª ×¢×‘×•×¨ {aoi_name}")
            image1 = self.satellite_processor.download_image(
                bbox, 
                date_ranges['historical']['from'], 
                date_ranges['historical']['to']
            )
            
            if not image1:
                raise Exception("×›×©×œ ×‘×”×•×¨×“×ª ×ª××•× ×” ×”×™×¡×˜×•×¨×™×ª")
            
            print(f"ğŸ“¥ ××•×¨×™×“ ×ª××•× ×” ×¢×“×›× ×™×ª ×¢×‘×•×¨ {aoi_name}")
            image2 = self.satellite_processor.download_image(
                bbox, 
                date_ranges['recent']['from'], 
                date_ranges['recent']['to']
            )
            
            if not image2:
                raise Exception("×›×©×œ ×‘×”×•×¨×“×ª ×ª××•× ×” ×¢×“×›× ×™×ª")
            
            # ×™×¦×™×¨×ª ×©××•×ª ×§×‘×¦×™×
            process_id = str(uuid.uuid4())[:8]
            filenames = self.generate_filenames(user_id, process_id)
            
            # ×©××™×¨×ª ×ª××•× ×•×ª
            image1_path = os.path.join('images', filenames['image1'])
            image2_path = os.path.join('images', filenames['image2'])
            heatmap_path = os.path.join('images', filenames['heatmap'])
            
            image1.save(image1_path, 'JPEG', quality=95)
            image2.save(image2_path, 'JPEG', quality=95)
            
            # ×™×¦×™×¨×ª ××¤×ª ×—×•× ×•×—×™×©×•×‘ ×©×™× ×•×™
            print(f"ğŸ”¥ ×™×•×¦×¨ ××¤×ª ×—×•× ×¢×‘×•×¨ {aoi_name}")
            self.satellite_processor.create_heatmap(image1, image2, heatmap_path)
            change_percentage = self.satellite_processor.calculate_change_percentage(image1, image2)
            
            # ×©××™×¨×ª ×ª×•×¦××•×ª
            metadata = {
                'date_range_1': date_ranges['historical'],
                'date_range_2': date_ranges['recent'],
                'location_description': aoi_name,
                'processing_time': datetime.now().isoformat(),
                'analysis_type': aoi_data['analysis_type'],
                'automatic': True,
                'change_percentage': change_percentage
            }
            
            analysis_id = self.db_manager.save_analysis(
                user_id=user_id,
                process_id=process_id,
                bbox_coordinates=bbox,
                image_filenames=filenames,
                metadata=metadata,
                aoi_id=aoi_id,
                tokens_used=0,
                is_automatic=True,
                change_percentage=change_percentage
            )
            
            # ×¢×“×›×•×Ÿ ×ª××¨×™×›×™ × ×™×ª×•×— ×©×œ AOI
            self.db_manager.update_aoi_analysis_date(aoi_id, increment_total=True)
            
            # ×¨×™×©×•× ×¤×¢×™×œ×•×ª
            self.db_manager.log_activity(user_id, 'automatic_analysis_completed', {
                'aoi_id': aoi_id,
                'aoi_name': aoi_name,
                'analysis_id': analysis_id,
                'change_percentage': change_percentage,
                'process_id': process_id
            }, description=f"× ×™×ª×•×— ××•×˜×•××˜×™ ×”×•×©×œ× ×¢×‘×•×¨ {aoi_name}")
            
            print(f"âœ… × ×™×ª×•×— ××•×˜×•××˜×™ ×”×•×©×œ× ×¢×‘×•×¨ {aoi_name} - ×©×™× ×•×™: {change_percentage:.2f}%")
            
            # ×‘×“×™×§×ª ×©×™× ×•×™ ××©××¢×•×ª×™
            if change_percentage > 10.0:
                print(f"ğŸš¨ ×–×•×”×” ×©×™× ×•×™ ××©××¢×•×ª×™ ×‘-{aoi_name}: {change_percentage:.2f}%")
                # ×›××Ÿ ××¤×©×¨ ×œ×”×•×¡×™×£ ×”×ª×¨×¢×•×ª (email, webhook, ×•×›×•')
            
            return True
            
        except Exception as e:
            print(f"âŒ × ×™×ª×•×— ××•×˜×•××˜×™ × ×›×©×œ ×¢×‘×•×¨ {aoi_name}: {e}")
            # ×¢×“×›×•×Ÿ ×ª××¨×™×š ×œ× ×™×¡×™×•×Ÿ ×××•×—×¨ ×™×•×ª×¨
            self.db_manager.update_aoi_analysis_date(aoi_id, increment_total=False)
            return False
    
    def generate_date_ranges(self):
        """×™×¦×™×¨×ª ×˜×•×•×—×™ ×ª××¨×™×›×™× ×œ×”×©×•×•××”"""
        end_date = datetime.now()
        
        # ×ª××¨×™×š ×¢×“×›× ×™ - 30 ×”×™××™× ×”××—×¨×•× ×™×
        start_date_recent = end_date - timedelta(days=30)
        
        # ×ª××¨×™×š ×”×™×¡×˜×•×¨×™ - ×œ×¤× ×™ 60-90 ×™××™×
        start_date_historical = end_date - timedelta(days=90)
        end_date_historical = end_date - timedelta(days=60)
        
        return {
            'historical': {
                'from': start_date_historical.strftime('%Y-%m-%d'),
                'to': end_date_historical.strftime('%Y-%m-%d')
            },
            'recent': {
                'from': start_date_recent.strftime('%Y-%m-%d'),
                'to': end_date.strftime('%Y-%m-%d')
            }
        }
    
    def generate_filenames(self, user_id, process_id):
        """×™×¦×™×¨×ª ×©××•×ª ×§×‘×¦×™× ×™×™×—×•×“×™×™×"""
        return {
            'image1': f"auto_user_{user_id}_image1_{process_id}.jpg",
            'image2': f"auto_user_{user_id}_image2_{process_id}.jpg",
            'heatmap': f"auto_user_{user_id}_heatmap_{process_id}.png"
        }
    
    def get_status(self):
        """×§×‘×œ×ª ××¦×‘ ×”×©×™×¨×•×ª"""
        return {
            'is_running': self.is_running,
            'check_interval_hours': self.check_interval_hours,
            'max_analyses_per_run': self.max_analyses_per_run,
            'scheduler_running': self.scheduler.running if hasattr(self.scheduler, 'running') else False
        }
    
    def force_analysis_for_aoi(self, aoi_id):
        """×”×¤×¢×œ×ª × ×™×ª×•×— ××™×™×“×™ ×¢×‘×•×¨ AOI ×¡×¤×¦×™×¤×™ (×œ×˜×¡×˜×™×)"""
        try:
            # ×§×‘×œ×ª × ×ª×•× ×™ AOI
            aois = self.db_manager.get_aois_for_analysis()
            aoi_data = next((aoi for aoi in aois if aoi['aoi_id'] == aoi_id), None)
            
            if not aoi_data:
                return False, "AOI ×œ× × ××¦× ××• ×œ× ×–××™×Ÿ ×œ× ×™×ª×•×—"
            
            success = self.run_automatic_analysis(aoi_data)
            return success, "× ×™×ª×•×— ×”×•×©×œ×" if success else "× ×™×ª×•×— × ×›×©×œ"
            
        except Exception as e:
            return False, f"×©×’×™××”: {e}"
    
    def cleanup_old_images(self, days_old=30):
        """× ×™×§×•×™ ×ª××•× ×•×ª ×™×©× ×•×ª (××•×¤×¦×™×•× ×œ×™)"""
        try:
            images_dir = 'images'
            if not os.path.exists(images_dir):
                return
            
            cutoff_date = datetime.now() - timedelta(days=days_old)
            deleted_count = 0
            
            for filename in os.listdir(images_dir):
                filepath = os.path.join(images_dir, filename)
                
                if os.path.isfile(filepath):
                    file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                    
                    if file_time < cutoff_date:
                        try:
                            os.remove(filepath)
                            deleted_count += 1
                        except Exception as e:
                            print(f"âŒ ×œ× × ×™×ª×Ÿ ×œ××—×•×§ {filename}: {e}")
            
            print(f"ğŸ§¹ × ×•×§×• {deleted_count} ×ª××•× ×•×ª ×™×©× ×•×ª")
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×ª××•× ×•×ª: {e}")
    
    def __del__(self):
        """× ×™×§×•×™ ××©××‘×™× ×‘×¡×’×™×¨×”"""
        if self.is_running:
            try:
                self.stop()
            except:
                pass